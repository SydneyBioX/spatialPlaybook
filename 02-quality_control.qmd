# Quality Control

```{r 02-code chunk timing, include = FALSE}
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- Sys.time()
    } else {
      # calculate the time difference after a chunk
      res <- difftime(Sys.time(), now, units = "secs")
      # return a character string to show the time in bold and right-aligned, with extra spacing
      paste("<div style='text-align: right;'><em>Time for this code chunk to run with ", nCores, "cores: ", round(res, 2), "s</div></em>")
    }
  }
}))
```

Variability in marker intensity across images is a common challenge in spatial imaging, often driven by technical factors like staining efficiency, imaging conditions, or sample preparation. For instance, a marker such as CD3 might appear overly bright in one sample and faint in another, even if the underlying biology is similar. These inconsistencies can blur the distinction between marker-positive and -negative cells, leading to misclassification and unreliable comparisons between and within samples.

Because raw intensities aren’t always directly comparable across or within images, quality control is an essential next step after segmentation. The [simpleSeg](https://www.bioconductor.org/packages/release/bioc/html/simpleSeg.html) package includes tools to support this process, with functions for visualising expression, detecting batch effects, and applying normalisation. These steps help harmonise marker distributions across samples, clarify cell populations, and improve the reliability of downstream analyses.

<!-- Steps: -->

<!-- 1.  Evaluate quality of cell segmentation with CellSPA (simpleSeg/cellSPA?) -->

<!-- 2.  How to qc image batch-effect (simpleSeg::normalizeCells) -->

<!-- 3.  How to qc patient batch-effect (simpleSeg::normalizeCells) -->

<!-- 4.  How to qc batch effects (scMerge) -->

```{r 02-load libraries, echo=FALSE, results="hide", warning=FALSE}
suppressPackageStartupMessages({
  library(tidySingleCellExperiment)
  library(simpleSeg)
  # library(scMerge)
  library(scater)
  library(ggplot2)
})
```

```{r 02-libraries, eval = FALSE}
# load required libraries
library(tidySingleCellExperiment)
library(simpleSeg)
library(scater)
library(ggplot2)
```

```{r 02-set parameters}
# set parameters
set.seed(51773)
use_mc <- TRUE
if (use_mc) {
   nCores <- max(ceiling(parallel::detectCores() / 2), 1)
} else {
  nCores <- 1
}
BPPARAM <- simpleSeg:::generateBPParam(nCores)
theme_set(theme_classic())
```

<!-- ## CellSPA: How do I determine segmentation quality? -->

<!-- [CellSPA](https://sydneybiox.github.io/CellSPA/) is an R package that provides an evaluation framework for *in situ* cell segmentation results. -->

## simpleSeg: Do my images have a batch effect?

First, let's load in the images we previously segmented out in the last section. The `SpatialDatasets` package conveniently provides the segmented out images for the [Ferguson 2022](datasets.qmd) dataset.

```{r 02-load ferguson data, warning = FALSE, message = FALSE}
# load in segmented data
fergusonSPE <- SpatialDatasets::spe_Ferguson_2022()
```

Next, we assess whether the marker intensities require transformation or normalisation. This step is important for two main reasons:

-   **Skewed distributions**: Marker intensities are often right-skewed, which can distort downstream analyses such as clustering or dimensionality reduction.

-   **Inconsistent scales across images**: Due to technical variation, the same marker may show very different intensity ranges across images. This can shift what’s considered "positive" or "negative" expression, making it difficult to label cells accurately.

By applying transformation and normalisation, we aim to stabilise variance and bring the data onto a more comparable scale across images.

Below, we extract marker intensities from the `counts` assay and take a closer look at the CD3 marker, which is typically expressed in T cells and is often used as a canonical marker to annotate T cell populations. This provides a useful starting point for assessing intensity distributions and spotting potential technical variation across samples.

We use density plots here because they offer a straightforward way to visualise the distribution of expression values across cells in each image, making it easier to compare overall signal shifts and detect batch effects.

```{r 02-plot CD3 density, fig.width=5, fig.height=5}
# plot densities of CD3 for each image
fergusonSPE |> 
  join_features(features = rownames(fergusonSPE), shape = "wide", assay = "counts") |> 
  ggplot(aes(x = CD3, colour = imageID)) + 
  geom_density() + 
  theme(legend.position = "none")
```

Here, we can see that the CD3 intensity distributions are highly skewed, making it difficult to distinguish CD3⁺ cells from CD3⁻ cells. Ideally, for a marker like CD3, we would expect to see a bimodal distribution—one peak corresponding to CD3⁻ cells (background or low expression) and another for CD3⁺ cells (true positive signal).

In addition to skewness, we also observe clear image-level batch effects. For example, the position and shape of the intensity peaks vary substantially between images, suggesting that what counts as “positive” expression in one image might fall below detection in another.

::: callout-tip
**What we're looking for**

1.  Do the CD3+ and CD3- peaks clearly separate out in the density plot? To ensure that downstream clustering goes smoothly, we want our cell type specific markers to show 2 distinct peaks representing our CD3+ and CD3- cells. If we see 3 or more peaks where we don't expect, this might be an indicator that further normalisation is required.
2.  Are our CD3+ and CD3- peaks consistent across our images? We want to make sure that our density plots for CD3 are largely the same across images so that a CD3+ cell in one image is equivalent to a CD3+ cell in another image.
:::

Another way to visualise batch effects is by applying dimensionality reduction techniques (like PCA or UMAP) to the marker expression data and plotting the cells in two dimensions. If there are no major batch effects, cells from different images should largely overlap or mix well in this reduced space. However, if strong batch effects are present, cells will tend to cluster by image rather than by biological similarity—indicating that technical variation is dominating the structure of the data.

```{r 02-plot UMAP, time_it = TRUE}
set.seed(51773)

# specify a subset of informative markers for UMAP and clustering
ct_markers <- c("podoplanin", "CD13", "CD31",
                "panCK", "CD3", "CD4", "CD8a",
                "CD20", "CD68", "CD16", "CD14", 
                "HLADR", "CD66a")

# perform dimension reduction using UMAP
fergusonSPE <- scater::runUMAP(
  fergusonSPE,
  subset_row = ct_markers,
  exprs_values = "counts"
)

# select a subset of images to plot
someImages <- unique(fergusonSPE$imageID)[c(1, 5, 10, 20, 30, 40)]

# UMAP by imageID
scater::plotReducedDim(
  fergusonSPE[, fergusonSPE$imageID %in% someImages],
  dimred = "UMAP",
  colour_by = "imageID"
)
```

In the UMAP plot, cells cluster by image rather than mixing uniformly, indicating the presence of batch effects. This suggests that technical variation between images is driving much of the separation, rather than true biological differences.

We can use the `normalizeCells` function from the `simpleSeg` package to correct for image-level batch effects. We specify the following parameters:

-   `transformation` is an optional argument which specifies the function to be applied to the data. We do not apply an arcsinh transformation here, as we already apply a square root transform in the `simpleSeg` function.
-   `method = c("trim99", "mean", PC1")` is an optional argument which specifies the normalisation method(s) to be performed. A comprehensive table of methods is provided below.
-   `assayIn = "counts"` is a required argument which specifies the name of the assay that contains our intensity data. In our context, this is called `counts`.

```{r 02-normalizeCells, fig.width=5, fig.height=5}
# leave out the nuclei markers from our normalisation process
useMarkers <- rownames(fergusonSPE)[!rownames(fergusonSPE) %in% c("DNA1", "DNA2", "HH3")]

# transform and normalise the marker expression of each cell type
fergusonSPE <- normalizeCells(fergusonSPE,
                        markers = useMarkers,
                        transformation = NULL,
                        method = c("trim99", "mean", "PC1"),
                        assayIn = "counts",
                        cores = nCores)
```

This modified data is then stored in the `norm` assay by default, but can be changed using the `assayOut` parameter.

::: callout-tip
**Choosing transformation and normalisation methods**

Not all datasets require the same transformation or normalisation strategy. Choosing the right one can depend on both the biological context and the source of technical variability.

1.  Do your marker intensities show strong skew or heavy tails? If so, applying a transformation (e.g., square root, log, or arcsinh) can help stabilise variance and separate low vs high signal populations.

2.  Do images cluster separately in the UMAP plots? This often points to batch effects, which may require normalisation across images using approaches like centering on the mean, scaling by standard deviation, or regression-based adjustments (e.g., removing PC1, removing the highest 1% of values, etc.).

3.  Are there markers you shouldn’t normalise? Nuclear markers like DNA1, DNA2, or HH3 often serve as internal references and typically aren’t normalised.

There’s no universal solution—experiment with different approaches, carefully examine the results, and focus on methods that best preserve biological meaning and interpretability rather than just achieving perfect statistical uniformity.
:::

#### `method` Parameters

| Method | Description |
|------------------------------------|:----------------------------------:|
| ["mean"]{style="font-family: 'Courier New', monospace;"} | [Divides the marker cellular marker intensities by their mean.]{style="font-family: 'Courier New', monospace;"} |
| ["minMax"]{style="font-family: 'Courier New', monospace;"} | [Subtracts the minimum value and scales markers between 0 and 1.]{style="font-family: 'Courier New', monospace;"} |
| ["trim99"]{style="font-family: 'Courier New', monospace;"} | [Sets the highest 1% of values to the value of the 99th percentile.\`]{style="font-family: 'Courier New', monospace;"} |
| ["PC1"]{style="font-family: 'Courier New', monospace;"} | [Removes the 1st principal component.]{style="font-family: 'Courier New', monospace;"} |

Multiple normalisation techniques can be applied within one call of the function, in the order specified by the user.

To check whether our transformation has worked, we can then plot the same density curve for the CD3 marker using the normalised data.

```{r 02-plot CD3 normalised}
# plot densities of CD3 for each image
fergusonSPE |> 
  join_features(features = rownames(fergusonSPE), shape = "wide", assay = "norm") |> 
  ggplot(aes(x = CD3, colour = imageID)) + 
  geom_density() + 
  theme(legend.position = "none")
```

In the plot above, the normalised data appeas more bimodal. We can observe one clear CD3- peak at around 0.00, and a CD3+ peak at 1.00. Image-level batch effects also appear to have been mitigated, since most peaks occur at around the same CD3 intensity.

::: callout-tip
**Questions revisited**

1.  Do the CD3+ and CD3- peaks clearly separate out in the density plot? If not, we can try optimising the transformation if the distribution looks heavily skewed.
2.  Are our CD3+ and CD3- peaks consistent across our images? We can try to be more stringent in our normalisation, such as by removing the 1st PC (`method = c(..., "PC1")`) or scaling the values for all images between 0 and 1 (`method = c(..., "minMax")`).
:::

We can also visualise the effect of normalisation on the UMAP, which shows that the cells from different images now overlap with each other to a much greater extent.

```{r 02-norm UMAP, time_it = TRUE}
set.seed(51773)

# perform dimension reduction using UMAP
fergusonSPE <- scater::runUMAP(
  fergusonSPE,
  subset_row = ct_markers,
  exprs_values = "norm",
  name = "normUMAP"
)

someImages <- unique(fergusonSPE$imageID)[c(1, 5, 10, 20, 30, 40)]

# UMAP by imageID
scater::plotReducedDim(
  fergusonSPE[, fergusonSPE$imageID %in% someImages],
  dimred = "normUMAP",
  colour_by = "imageID"
)
```

<!-- ## scMerge: Combining multiple spatial datasets -->

<!-- A common question that pops up when analysing spatial datasets is: can I combine multiple spatial datasets? -->

## sessionInfo

```{r}
sessionInfo()
```
