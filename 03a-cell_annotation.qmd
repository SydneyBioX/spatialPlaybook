# Unsupervised clustering for cell annotation

```{r 03a-code chunk timing, include = FALSE}
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- Sys.time()
    } else {
      # calculate the time difference after a chunk
      res <- difftime(Sys.time(), now, units = "secs")
      # return a character string to show the time in bold and right-aligned, with extra spacing
      paste("<div style='text-align: right;'><em>Time for this code chunk to run with ", nCores, "cores: ", round(res, 2), "s</div></em>")
    }
  }
}))
```

Cell type annotation is the process of assigning each cell a specific identity based on its marker expression profile. Identifying cell types is a key step in many spatial analysis workflows, as it shapes how we analyse tissue composition, measure cell-cell interactions, and track disease mechanisms.

But cell type annotation isn’t always clear-cut. Marker expression often varies along a continuum rather than forming distinct groups, and overlapping profiles combined with technical noise can blur boundaries, making it tricky to assign confident labels. These uncertainties can cascade through your analysis, affecting clustering, interpretation, and downstream results.

There are two main ways to assign cell types: unsupervised clustering and supervised annotation. Clustering groups cells based on similarity in marker expression, which can uncover novel or unexpected populations—but biological expertise is often necessary to interpret and label those clusters. Annotation, on the other hand, leverages reference datasets from well-characterised samples to directly assign cell type labels, improving consistency and reproducibility, though it depends on having a relevant and high-quality reference.

Both approaches come with trade-offs. Clustering can miss subtle or rare populations and is sensitive to parameter choices, such as the number of clusters, which can greatly influence results. Annotation risks misclassifying cells if the reference doesn’t capture all the diversity in the sample. This playbook focuses on unsupervised clustering—covering how to select appropriate parameters, determine the optimal number of clusters, and interpret results effectively.

<!-- Steps: -->

<!-- 1.  Clustering vs annotation -->

<!-- 2.  Clustering with FuseSOM -->

<!-- 3.  Cluster annotation with pheatmap -->

<!-- 4.  Cell annotation with scClassify -->

<!-- 5.  Selecting a reference dataset with scClassify -->

```{r 03a-load libraries, echo=FALSE, results="hide", warning=FALSE}
suppressPackageStartupMessages({
  library(FuseSOM)
  library(STexampleData)
  library(MLmetrics)
  library(simpleSeg)
  library(scuttle)
  library(ggplot2)
  library(SingleCellExperiment)
})
```

```{r 03a-libraries, eval = FALSE}
# load required libraries
library(FuseSOM)
library(STexampleData)
library(MLmetrics)
library(simpleSeg)
library(scuttle)
library(ggplot2)
library(SingleCellExperiment)
```

```{r 03a-set parameters}
# set parameters
set.seed(51773)

# whether to use multiple cores (recommended)
use_mc = TRUE
is_windows = .Platform$OS.type == "windows"

if (use_mc) {
  nCores = max(ceiling(parallel::detectCores() / 2), 1)
  
  if (nCores == 1) {
    BPPARAM = SerialParam()
  } else if (is_windows) {
    BPPARAM = SnowParam(workers = nCores, type = "SOCK")
  } else {
    BPPARAM = MulticoreParam(workers = nCores)
  }
} else {
  BPPARAM = SerialParam()
}

theme_set(theme_classic())
```

## Clustering with FuseSOM

Clustering of highly multiplexed in situ imaging cytometry data can be performed using tools like [FuseSOM](https://www.bioconductor.org/packages/release/bioc/html/FuseSOM.html), an unsupervised method that combines a Self Organising Map architecture with MultiView integration of correlation-based metrics for enhanced robustness and accuracy. `FuseSOM` supports multiple data structures, including `SingleCellExperiment` and `SpatialExperiment` objects, as well as `DataFrames.`

<img src="images/FuseSOM_fig1.jpeg" align="center" style="height:200px; border: 0px"/>

### FuseSOM Matrix Input

To demonstrate the functionality of `FuseSOM`, we will use the [Risom 2022](datasets.qmd) dataset, which profiles the spatial landscape of ductal carcinoma in situ (DCIS), a precursor to invasive breast cancer (IBC). We will be using the markers used in the original study to perform clustering.

We’ll start by running `FuseSOM` on a `DataFrame`, then demonstrate how to apply it to `SingleCellExperiment` and `SpatialExperiment` objects.

```{r 03a-load Risom data, warning = FALSE, message = FALSE}
# load in the data
data("risom_dat")

# define the markers of interest (highlighted in the original study)
risomMarkers <- c('CD45','SMA','CK7','CK5','VIM','CD31','PanKRT','ECAD',
                   'Tryptase','MPO','CD20','CD3','CD8','CD4','CD14','CD68','FAP',
                   'CD36','CD11c','HLADRDPDQ','P63','CD44')

# we will be using the manual_gating_phenotype as the true cell type to gauge 
# performance
names(risom_dat)[names(risom_dat) == 'manual_gating_phenotype'] <- 'CellType'
```

Now that we have loaded the data and defined the markers of interest, we can run the `FuseSOM` algorithm using the `runFuseSOM` function. We specify the number of clusters (or cell types) to be 23 based on prior domain knowledge. The output contains the cluster labels as well as the `Self Organizing Map` model.

```{r 03a-run FuseSOM, message=FALSE, warning=FALSE}
risomRes <- runFuseSOM(data = risom_dat, markers = risomMarkers, 
                        numClusters = 23)
```

Let's look at the distribution of the clusters.

```{r 03a-clusters frequency table}
# get the distribution of the clusters
round(table(risomRes$clusters)/sum(table(risomRes$clusters)), 2)
```

It appears that 32% of cells have been assigned to `cluster_1`. Next, lets generate a heatmap of the marker expression for each cluster using the `markerHeatmap` function.

```{r 03a-cluster heatmap, fig.align='center', fig.height=7, fig.width=10, dev='png'}
risomHeat <- FuseSOM::markerHeatmap(data = risom_dat, markers = risomMarkers,
                            clusters = risomRes$clusters, clusterMarkers = TRUE)
```

At this stage, we can evaluate whether our clustering makes biological sense. For example, `cluster_10` shows high expression of CD14, a marker for monocytes, so it’s reasonable to annotate cells in this cluster as monocytes. Similarly, `cluster_14`, with elevated Tryptase expression, could be annotated as mast cells.

In some cases, the clusters cannot be clearly distinguished by a specific cell type marker. `cluster_9` shows high expression of CD20, CD45, CD8, and CD3, which are canonical markers for both B cell and T cell populations. Additionally, clusters like `cluster_3` and `cluster_4` exhibit **smearing**, meaning their marker expression profiles overlap substantially with multiple cell types. This can indicate mixed or transitional populations, technical noise, or insufficient resolution in clustering.

::: {.callout-tip title="Common problems with clustering"}
**How do I identify imperfect clustering?**

1.  Do our cell-type specific markers clearly separate out by cluster? We expect to see discrete expression of our markers in specific cell types, e.g., CD4 being expressed in T cells exclusively.
2.  If we instead see "smearing" of our markers across clusters, where several clusters express high levels of a cell type specific marker such as CD4, it is likely a normalisation issue.
:::

::: {.callout-tip title="Remedying imperfect clustering"}
**Three common issues which cause imperfect clustering have been outlined below:**

1.  **Imperfect segmentation**: excessive lateral marker spill over can severely impact downstream clustering, as cell type specific markers leak into nearby cells. This should largely be diagnosed in the segmentation step and will need to be fixed by optimising the upstream segmentation algorithm.
2.  **Imperfect normalization**: excessively variable intensities across images could cause issues in the normalization process. This can generally be diagnosed with density plots and box plots for specific markers across images and can be fixed by identifying the exact issue, e.g. extremely high values for a small subset of images, and choosing a normalization strategy to remove/reduce this effect.
3.  **Imperfect clustering**: setting the number of clusters to be low or too high could lead to imperfect clustering. This is usually diagnosed by clusters which either express too many markers very highly or express too few markers, and is usually remedied by choosing an ideal `k` based on an elbow plot described below.
:::

In practice, clustering and annotation are rarely one-and-done. A common strategy is to start by identifying broad cell populations—like T cells, B cells, or monocytes—using a general set of markers. Once these groups are defined, you can isolate specific populations and re-cluster them using more focused markers to distinguish finer subtypes, such as CD4+ and CD8+ T cells. This stepwise approach helps improve resolution and leads to more accurate and informative cell type annotations.

### Using FuseSOM to estimate the number of clusters

Before clustering, it’s helpful to estimate how many clusters best represent the structure of your data. Elbow plots are a common way to guide this decision. On these plots, the x-axis shows the number of clusters (`k`), while the y-axis shows a clustering quality metric—such as within-cluster variation, silhouette width, or another distance-based score. As `k` increases, the metric usually improves, but only up to a point. The “elbow” refers to where this improvement begins to level off, suggesting that adding more clusters beyond this point gives diminishing returns. That inflection point is typically interpreted as the optimal number of clusters.

We can generate these plots using the `estimateNumCluster` function from the `FuseSOM` package, which supports both a discriminant-based method and a range of distance-based metrics:

-   Discriminant based method
    -   This method attempts to find a projection of the data that maximizses the separation between clusters, helping to identify the most distinct groupings in the dataset.
-   Distance based methods
    -   Gap Statistic: compares the total within-cluster variation for different values of k with expected values under a null reference distribution.
    -   Jump Statistic: measures how much the data “jumps” or changes structure when moving from `k` to `k+1` clusters.
    -   Slope Statistic: looks at the rate of change (slope) in clustering quality metrics as `k` increases.
    -   Within Cluster Dissimilarity Statistic: quantifies how similar the data points are within each cluster.
    -   The Silhouette Statistic: combines measures of cohesion (how close points are within a cluster) and separation (how far apart clusters are).

By setting `method = c("Discriminant", "Distance")`, we can run both approaches and compare their suggested number of clusters. This gives a more comprehensive view of the clustering landscape, especially when the true number of underlying cell types is unknown.

```{r 03a-estimate k, message=FALSE, warning=FALSE}
# lets estimate the number of clusters using all the methods
# original clustering has 23 clusters so we will set kseq from 2:25
# we pass it the SOM model generated in the previous step
risomKest <- estimateNumCluster(data = risomRes$model, kSeq = 2:25, 
                                  method = c("Discriminant", "Distance"))
```

We can then use this result to determine the best number of clusters for this dataset based on the different metrics.

```{r 03a-discriminant estimate}
# what is the best number of clusters determined by the discriminant method?
risomKest$Discriminant 
```

According to the Discriminant method, the optimal number of clusters is 7.

We can use the `optiPlot()` function to generate an elbow plot with the optimal number of clusters for the distance based methods.

<div>

```{r 03a-elbow plots}
# we can plot the results using the optiplot function
pSlope <- optiPlot(risomKest, method = 'slope')
pSlope
pJump <- optiPlot(risomKest, method = 'jump')
pJump
pWcd <- optiPlot(risomKest, method = 'wcd')
pWcd
pGap <- optiPlot(risomKest, method = 'gap')
pGap
pSil <- optiPlot(risomKest, method = 'silhouette')
pSil

```

</div>

From the plots, we see that the Jump statistic almost perfectly identifies the expected number of clusters, showing a clear and sharp increase at `k = 24`. This suggests that the structure of the data changes meaningfully at that point, making it an effective indicator of the optimal number of clusters in this case. The Gap statistic also performs relatively well, selecting a lower value (15 clusters), which may still be reasonable depending on the biological context and the presence of closely related subpopulations. In contrast, the other distance-based methods—such as the Silhouette, Slope, and Within-Cluster Dissimilarity statistics—significantly underestimate the number of clusters.

Overall, these results highlight the importance of testing multiple metrics and not relying on a single method. It's also helpful to complement these quantitative results with biological interpretation—e.g., inspecting marker expression within clusters—to ensure that the chosen `k` aligns with known or expected cell types.

::: {.callout-tip title="Estimating the value of k"}
1.  How do we choose our `k`? We're generally looking for the `k` before the point of greatest inflection, or the point beyond which increasing `k` results in minimal improvement to clustering quality.
2.  Is there one best choice for `k`? There can be several options of `k` if there are several points of inflection. Choose the `k` which best reflects the number of clusters you expect to get from the tissue. For instance, if you are interested in broader cell populations, you might pick a lower value of `k` , and if you are interested in identifying subpopulations, you might pick a larger value for `k` .
:::

### FuseSOM with SingleCellExperiment object as input

The FuseSOM algorithm is also equipped to take in a `SingleCellExperiment` or `SpatialExperiment` object as input. The results of the pipeline will be written to either the `metadata` or the `colData` fields.

First, we create a `SingleCellExperiment` object using the Risom 2022 data.

```{r 03a-create Risom SCE, message=FALSE, warning=FALSE}
# create an SCE object using Risom 2022 data
colDat <- risom_dat[, setdiff(colnames(risom_dat), risomMarkers)]
sce <- SingleCellExperiment(assays = list(counts = t(risom_dat[, names(risom_dat) != "CellType"])),
                                 colData = colDat)

sce
```

Next, we pass it to the `runFuseSOM` function. Here, we can provide the assay in which the data is stored (`counts`) and specify the column to store the clusters in using `clusterCol = "clusters"`. The `Self Organizing Map` that is generated will be stored in the metadata field.

```{r 03a-FuseSOM with SCE, message=FALSE, warning=FALSE}
risomRessce <- runFuseSOM(sce, markers = risomMarkers, clusterCol = "clusters",
                          assay = 'counts', numClusters = 23, verbose = FALSE)

colnames(colData(risomRessce))
names(metadata(risomRessce))
```

Notice how the there is now a `clusters` column in the `colData` and a SOM field in the metadata.

If necessary, you can run `runFuseSOM` with a new cluster number and specify a new `clusterCol`. If `clusterCol` contains a new name, the new clusters will be stored in the new column. Otherwise, it will overwrite the the current `clusters` column. Running `FuseSOM` on the same `SingleCellExperiment` object will overwrite the existing SOM field in the metadata.

Just like before, we can plot a heatmap of the resulting clusters across all markers.

```{r 03a-SCE heatmap, fig.height = 10}
data <- risom_dat[, risomMarkers] # get the original data used
clusters <- colData(risomRessce)$clusters # extract the clusters from the SCE object

# generate the heatmap
risomHeatsce <- markerHeatmap(data = risom_dat, markers = risomMarkers,
                            clusters = clusters, clusterMarkers = TRUE)
```

Or we can directly plot from the SCE using the `scater` package.

```{r 03a-scater heatmap, fig.height = 10}
# Visualise marker expression in each cluster.
scater::plotGroupedHeatmap(
  risomRessce,
  features = risomMarkers,
  group = "clusters",
  exprs_values = "counts",
  center = TRUE,
  scale = TRUE,
  zlim = c(-3, 3),
  cluster_rows = FALSE,
  block = "clusters"
)
```

### Using FuseSOM to estimate the number of clusters for SingleCellExperiment objects

Just like before, we will use `estimateNumCluster` on our Risom `SingleCellExperiment` object.

```{r 03a-estimateNumClusters for SCE}
# lets estimate the number of clusters using all the methods
# original clustering has 23 clusters so we will set kseq from 2:25
risomRessce <- estimateNumCluster(data = risomRessce, kSeq = 2:25, 
                                  method = c("Discriminant", "Distance"))

names(metadata(risomRessce))
```

The metadata now contains a `clusterEstimation` field which holds the results from the `estimateNumCluster` function.

We can assess the results of cluster estimation as below.

```{r 03a-discriminant results SCE, fig.align='center', fig.height=5, fig.width=6, dev='png'}
# what is the best number of clusters determined by the discriminant method?
metadata(risomRessce)$clusterEstimation$Discriminant 
```

According to the discrminant method, the optimal number of clusters is 7.

```{r 03a-optiPlot SCE, warning = FALSE, message = FALSE}
# we can plot the results using the optiplot function
pSlope <- optiPlot(risomRessce, method = 'slope')
pSlope
pJump <- optiPlot(risomRessce, method = 'jump')
pJump
pWcd <- optiPlot(risomRessce, method = 'wcd')
pWcd
pGap <- optiPlot(risomRessce, method = 'gap')
pGap
pSil <- optiPlot(risomRessce, method = 'silhouette')
pSil

```

Again, we see that the `Jump` statistic almost perfectly captures the correct number of clusters with 24 clusters. The `Gap` method is a close second with 15 clusters. All the other methods significantly underestimate the number of clusters.

## sessionInfo

```{r}
sessionInfo()
```
